import torch.nn as nn
import torch.nn.functional as F

class VGGNet(nn.Module):
	def __init__(self, num_classes=2, init_weights=True):
		super(VGGNet, self).__init__()
		self.num_classes = num_classes
		self.conv1_1 =nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=3, padding=1)
		self.relu1_1 =nn.ReLU(inplace = True)
		self.conv1_2 =nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, padding=1)
		self.relu1_2 =nn.ReLU(inplace = True)
		self.max1    =nn.MaxPool2d(kernel_size = 2, stride = 2)
		self.conv2_1 =nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, padding=1)
		self.relu2_1 =nn.ReLU(inplace = True)
		self.conv2_2 =nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size=3, padding=1)
		self.relu2_2 =nn.ReLU(inplace = True)
		self.max2    =nn.MaxPool2d(kernel_size = 2, stride = 2)
		self.conv3_1 =nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=3, padding=1)
		self.relu3_1 =nn.ReLU(inplace = True)
		self.conv3_2 =nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size=3, padding=1)
		self.relu3_2 =nn.ReLU(inplace = True)
		self.conv3_3 =nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size=3, padding=1)
		self.relu3_3 =nn.ReLU(inplace = True)
		self.max3    =nn.MaxPool2d(kernel_size = 2, stride = 2)
		self.conv4_1 =nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size=3, padding=1)
		self.relu4_1 =nn.ReLU(inplace = True)
		self.conv4_2 =nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size=3, padding=1)
		self.relu4_2 =nn.ReLU(inplace = True)
		self.conv4_3 =nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size=3, padding=1)
		self.relu4_3 =nn.ReLU(inplace = True)
		self.max4    =nn.MaxPool2d(kernel_size = 2, stride = 2)
		self.conv5_1 =nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size=3, padding=1)
		self.relu5_1 =nn.ReLU(inplace = True)
		self.conv5_2 =nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size=3, padding=1)
		self.relu5_2 =nn.ReLU(inplace = True)
		self.conv5_3 =nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size=3, padding=1)
		self.relu5_3 =nn.ReLU(inplace = True)
		self.max5    =nn.MaxPool2d(kernel_size = 2, stride = 2)
		self.fc1     =nn.Linear(512*7*7, 1024)
		self.relu6_1 =nn.ReLU(inplace = True)
		self.fc2     =nn.Linear(1024, 100)
		self.relu6_2 =nn.ReLU(inplace = True)
		self.fc3     =nn.Linear(100, self.num_classes)

	def forward(self, x):
		x = self.conv1_1(x)
		x = self.relu1_1(x)
		x = self.conv1_2(x)
		x = self.relu1_2(x)
		x = self.max1(x)
		x = self.conv2_1(x)
		x = self.relu2_1(x)
		x = self.conv2_2(x)
		x = self.relu2_2(x)
		x = self.max2(x)
		x = self.conv3_1(x)
		x = self.relu3_1(x)
		x = self.conv3_2(x)
		x = self.relu3_2(x)
		x = self.conv3_3(x)
		x = self.relu3_3(x)
		x = self.max3(x)
		x = self.conv4_1(x)
		x = self.relu4_1(x)
		x = self.conv4_2(x)
		x = self.relu4_2(x)
		x = self.conv4_3(x)
		x = self.relu4_3(x)
		x = self.max4(x)
		x = self.conv5_1(x)
		x = self.relu5_1(x)
		x = self.conv5_2(x)
		x = self.relu5_2(x)
		x = self.conv5_3(x)
		x = self.relu5_3(x)
		x = self.max5(x)
		x = x.view(x.size(0), -1)
		x = self.fc1(x)
		x = self.relu6_1(x)
		x = self.fc2(x)
		x = self.relu6_2(x)
		x = self.fc3(x)
		return x

	def initialize_weights(self):
		for m in self.modules():
			if isinstance(m, nn.Conv2d):
				nn.init.kaiming_normal_(m.weight.data)
				if m.bias is not None:
					m.bias.data.zero_()
			elif isinstance(m, nn.Linear):
				nn.init.normal_(m.weight.data, 0, 0.1)
				m.bias.data.zero_()